{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65342115",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Conv2D, MaxPooling2D, Flatten,\n\u001b[0;32m     11\u001b[0m                                      Dense, Dropout, BatchNormalization)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Facial Expression Recognition using FER-2013 Dataset \n",
    "\n",
    "# Step 1: Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten,\n",
    "                                     Dense, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 2: Load and Inspect the Dataset\n",
    "def load_and_inspect_data(dataset_path):\n",
    "    \"\"\"Load the FER-2013 dataset and inspect its structure\"\"\"\n",
    "    try:\n",
    "        print(\"Loading FER-2013 dataset...\")\n",
    "        fer_df = pd.read_csv(dataset_path)\n",
    "        \n",
    "        print(f\"Dataset shape: {fer_df.shape}\")\n",
    "        print(f\"Columns: {fer_df.columns.tolist()}\")\n",
    "        print(f\"First few rows:\")\n",
    "        print(fer_df.head())\n",
    "        \n",
    "        # Check for missing values\n",
    "        print(f\"\\nMissing values:\\n{fer_df.isnull().sum()}\")\n",
    "        \n",
    "        # Check emotion distribution\n",
    "        if 'emotion' in fer_df.columns:\n",
    "            print(f\"\\nEmotion distribution:\")\n",
    "            print(fer_df['emotion'].value_counts().sort_index())\n",
    "        \n",
    "        return fer_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Update this path to your actual dataset location\n",
    "dataset_path = 'fer2013.csv' \n",
    "fer_df = load_and_inspect_data(dataset_path)\n",
    "\n",
    "# Step 3: Improved Data Preprocessing\n",
    "def prepare_data(df):\n",
    "    \"\"\"Prepare images and labels from the FER-2013 dataset\"\"\"\n",
    "    try:\n",
    "        # Convert pixel strings to numpy arrays\n",
    "        print(\"Converting pixel data to images...\")\n",
    "        pixel_series = df['pixels'].apply(lambda pixel_str: np.fromstring(pixel_str, sep=' '))\n",
    "        image_array = np.stack(pixel_series.to_numpy())\n",
    "        \n",
    "        # Reshape and normalize\n",
    "        image_array = image_array.reshape(-1, 48, 48, 1).astype('float32') / 255.0\n",
    "        \n",
    "        # Convert labels to one-hot encoding\n",
    "        label_array = pd.get_dummies(df['emotion']).values\n",
    "        \n",
    "        print(f\"Images shape: {image_array.shape}\")\n",
    "        print(f\"Labels shape: {label_array.shape}\")\n",
    "        \n",
    "        return image_array, label_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preparation: {e}\")\n",
    "        return None, None\n",
    "\n",
    "if fer_df is not None:\n",
    "    images, labels = prepare_data(fer_df)\n",
    "else:\n",
    "    print(\"Cannot proceed without dataset. Please check the dataset path.\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Enhanced Data Visualization\n",
    "emotion_names = {\n",
    "    0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\",\n",
    "    4: \"Sad\", 5: \"Surprise\", 6: \"Neutral\"\n",
    "}\n",
    "\n",
    "def visualize_data(images, labels, emotion_names):\n",
    "    \"\"\"Visualize sample images and emotion distribution\"\"\"\n",
    "    # Sample images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot sample images\n",
    "    plt.subplot(2, 2, (1, 2))\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i in range(8):\n",
    "        row, col = i // 4, i % 4\n",
    "        axes[row, col].imshow(images[i].reshape(48, 48), cmap='gray')\n",
    "        axes[row, col].set_title(f\"Emotion: {emotion_names[np.argmax(labels[i])]}\")\n",
    "        axes[row, col].axis('off')\n",
    "    plt.suptitle(\"Sample Images from FER-2013 Dataset\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot emotion distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    emotion_counts = [np.sum(np.argmax(labels, axis=1) == i) for i in range(7)]\n",
    "    plt.bar(range(7), emotion_counts, color='skyblue')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Emotions in Dataset')\n",
    "    plt.xticks(range(7), [emotion_names[i] for i in range(7)], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_data(images, labels, emotion_names)\n",
    "\n",
    "# Step 5: Improved Data Splitting\n",
    "print(\"Splitting dataset...\")\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "    temp_images, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {train_images.shape[0]} samples\")\n",
    "print(f\"Validation set: {val_images.shape[0]} samples\")\n",
    "print(f\"Test set: {test_images.shape[0]} samples\")\n",
    "\n",
    "# Step 6: Enhanced Data Augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# Step 7: Improved CNN Model Architecture\n",
    "def create_cnn_model(input_shape=(48, 48, 1), num_classes=7):\n",
    "    \"\"\"Create an improved CNN model for facial expression recognition\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "expression_model = create_cnn_model()\n",
    "\n",
    "# Step 8: Compile the Model\n",
    "expression_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"Model Architecture:\")\n",
    "expression_model.summary()\n",
    "\n",
    "# Step 9: Enhanced Training with Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=0.00001)\n",
    "]\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "training_history = expression_model.fit(\n",
    "    data_generator.flow(train_images, train_labels, batch_size=32),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 10: Save the Model\n",
    "model_save_path = 'fer2013_expression_model.h5'\n",
    "expression_model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Step 11: Comprehensive Model Evaluation\n",
    "def evaluate_model(model, test_images, test_labels, emotion_names):\n",
    "    \"\"\"Evaluate the model and generate comprehensive reports\"\"\"\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    predicted_probs = model.predict(test_images)\n",
    "    predicted_classes = np.argmax(predicted_probs, axis=1)\n",
    "    true_classes = np.argmax(test_labels, axis=1)\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_classes, predicted_classes, \n",
    "                              target_names=[emotion_names[i] for i in range(7)]))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[emotion_names[i] for i in range(7)],\n",
    "                yticklabels=[emotion_names[i] for i in range(7)])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return test_accuracy, predicted_classes, true_classes\n",
    "\n",
    "test_accuracy, predicted_classes, true_classes = evaluate_model(\n",
    "    expression_model, test_images, test_labels, emotion_names\n",
    ")\n",
    "\n",
    "# Step 12: Enhanced Visualization of Training History\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history with improved visualizations\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    plt.title('Model Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.title('Model Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Learning rate plot (if available)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'lr' in history.history:\n",
    "        plt.plot(history.history['lr'], label='Learning Rate', color='green')\n",
    "        plt.title('Learning Rate Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Learning Rate\\nNot Available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(training_history)\n",
    "\n",
    "# Step 13: Additional Analysis and Insights\n",
    "def analyze_predictions(predicted_classes, true_classes, emotion_names):\n",
    "    \"\"\"Analyze prediction patterns and provide insights\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ADDITIONAL ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for i in range(7):\n",
    "        class_mask = true_classes == i\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_accuracy = np.mean(predicted_classes[class_mask] == true_classes[class_mask])\n",
    "            print(f\"{emotion_names[i]}: {class_accuracy:.4f}\")\n",
    "    \n",
    "    # Most confused emotions\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(\"\\nMost Confused Emotion Pairs:\")\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                confusion_rate = cm[i, j] / np.sum(cm[i, :])\n",
    "                if confusion_rate > 0.1:  # Show confusions > 10%\n",
    "                    print(f\"{emotion_names[i]} â†’ {emotion_names[j]}: {confusion_rate:.2%}\")\n",
    "\n",
    "analyze_predictions(predicted_classes, true_classes, emotion_names)\n",
    "\n",
    "# Step 14: Suggestions for Improvement\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUGGESTIONS FOR IMPROVEMENT\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "1. Transfer Learning: Use pre-trained models like VGG16, ResNet50, or MobileNet\n",
    "2. Advanced Architectures: Try ResNet, DenseNet, or EfficientNet\n",
    "3. Ensemble Methods: Combine multiple models for better performance\n",
    "4. Data Augmentation: Experiment with more sophisticated augmentation techniques\n",
    "5. Hyperparameter Tuning: Use tools like Keras Tuner or Optuna\n",
    "6. Real-time Implementation: Integrate with OpenCV for live emotion detection\n",
    "7. Cross-validation: Use k-fold cross-validation for more robust evaluation\n",
    "8. Attention Mechanisms: Add attention layers to focus on important facial features\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"Model training and evaluation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
